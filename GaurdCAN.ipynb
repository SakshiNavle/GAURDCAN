{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14347305,"sourceType":"datasetVersion","datasetId":9160905},{"sourceId":14356102,"sourceType":"datasetVersion","datasetId":9167004}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# 1. Load the dataset\ndf = pd.read_csv('/kaggle/input/os-hard-mode-iso-csv/dos_hard_mode_iso.csv')\n\n# 2. Preprocessing\n# Select features: ID, DLC bytes, and Delta_T\nfeatures = ['ID_int', 'DLC0', 'DLC1', 'DLC2', 'DLC3', 'DLC4', 'DLC5', 'DLC6', 'DLC7', 'Delta_T']\nX = df[features].values\ny = df['Label'].values\n\n# Scaling is crucial for Neural Networks\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# 3. Create Sequences (Sliding Window)\n# LSTMs require input shape: (samples, time_steps, features)\ndef create_sequences(data, labels, window_size=10):\n    X_seq, y_seq = [], []\n    for i in range(len(data) - window_size):\n        X_seq.append(data[i:i + window_size])\n        y_seq.append(labels[i + window_size])\n    return np.array(X_seq), np.array(y_seq)\n\nWINDOW_SIZE = 10  # Look back at the last 10 messages\nX_seq, y_seq = create_sequences(X_scaled, y, window_size=WINDOW_SIZE)\n\n# 4. Train-Test Split\nX_train, X_test, y_train, y_test = train_test_split(\n    X_seq, y_seq, test_size=0.2, random_state=42, stratify=y_seq\n)\n\n# 5. Build the LSTM Model\nmodel = Sequential([\n    LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True),\n    Dropout(0.2),\n    LSTM(32),\n    Dropout(0.2),\n    Dense(16, activation='relu'),\n    Dense(1, activation='sigmoid') # Binary output: 0 (Normal) or 1 (DoS)\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# 6. Train the Model\nprint(\"Starting LSTM training...\")\nhistory = model.fit(\n    X_train, y_train,\n    epochs=10,\n    batch_size=64,\n    validation_split=0.1,\n    verbose=1\n)\n\n# 7. Evaluation\ny_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n\nprint(\"\\n--- LSTM Performance ---\")\nprint(classification_report(y_test, y_pred))\n\n# 8. Save the model\nmodel.save('dos_lstm_model.h5')\nprint(\"Model saved as dos_lstm_model.h5\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-31T14:19:27.661946Z","iopub.execute_input":"2025-12-31T14:19:27.662270Z","iopub.status.idle":"2025-12-31T14:21:16.075816Z","shell.execute_reply.started":"2025-12-31T14:19:27.662246Z","shell.execute_reply":"2025-12-31T14:21:16.074742Z"}},"outputs":[{"name":"stderr","text":"2025-12-31 14:19:31.375333: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767190771.606070      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767190771.670862      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stdout","text":"Starting LSTM training...\nEpoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"2025-12-31 14:19:49.768621: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.8376 - loss: 0.3589 - val_accuracy: 0.9076 - val_loss: 0.2381\nEpoch 2/10\n\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9087 - loss: 0.2421 - val_accuracy: 0.9130 - val_loss: 0.2270\nEpoch 3/10\n\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9114 - loss: 0.2332 - val_accuracy: 0.9144 - val_loss: 0.2235\nEpoch 4/10\n\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9111 - loss: 0.2318 - val_accuracy: 0.9138 - val_loss: 0.2254\nEpoch 5/10\n\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9108 - loss: 0.2314 - val_accuracy: 0.9130 - val_loss: 0.2246\nEpoch 6/10\n\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9101 - loss: 0.2300 - val_accuracy: 0.9130 - val_loss: 0.2226\nEpoch 7/10\n\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9100 - loss: 0.2318 - val_accuracy: 0.9132 - val_loss: 0.2236\nEpoch 8/10\n\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9127 - loss: 0.2264 - val_accuracy: 0.9136 - val_loss: 0.2236\nEpoch 9/10\n\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9097 - loss: 0.2309 - val_accuracy: 0.9130 - val_loss: 0.2223\nEpoch 10/10\n\u001b[1m676/676\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9107 - loss: 0.2278 - val_accuracy: 0.9142 - val_loss: 0.2236\n\u001b[1m376/376\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\n--- LSTM Performance ---\n              precision    recall  f1-score   support\n\n           0       0.93      0.94      0.93      7998\n           1       0.88      0.85      0.87      4012\n\n    accuracy                           0.91     12010\n   macro avg       0.90      0.90      0.90     12010\nweighted avg       0.91      0.91      0.91     12010\n\nModel saved as dos_lstm_model.h5\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import classification_report\n\n# 1. LOAD the data from the path string into a numpy array\n# Your error shows the path is '/kaggle/working/X_test2.npy'\nprint(\"Loading X_test data from disk...\")\nX_test_loaded = np.load('/kaggle/working/X_test2.npy')\ny_test_loaded = np.load('/kaggle/working/y_test2.npy') \n\nprint(f\"Data loaded. Shape: {X_test_loaded.shape}\")\n\n# 2. Make Predictions with the Base Model\nprint(\"Predicting with Base Model...\")\n# Use the LOADED data, not the string path\ny_probs = base_model.predict(X_test_loaded, verbose=0)\ny_pred_base = (y_probs > 0.5).astype(int)\n\n# 3. Print the Performance Report\nprint(\"\\n\" + \"=\"*35)\nprint(\"   BASE MODEL PERFORMANCE (FP32)\")\nprint(\"=\"*35)\nprint(classification_report(y_test_loaded, y_pred_base, target_names=['Normal', 'DoS Attack']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T16:59:46.944728Z","iopub.execute_input":"2025-12-31T16:59:46.945069Z","iopub.status.idle":"2025-12-31T16:59:49.152406Z","shell.execute_reply.started":"2025-12-31T16:59:46.945042Z","shell.execute_reply":"2025-12-31T16:59:49.151572Z"}},"outputs":[{"name":"stdout","text":"Loading X_test data from disk...\nData loaded. Shape: (12010, 10, 10)\nPredicting with Base Model...\n\n===================================\n   BASE MODEL PERFORMANCE (FP32)\n===================================\n              precision    recall  f1-score   support\n\n      Normal       0.91      0.96      0.94      7996\n  DoS Attack       0.90      0.82      0.86      4014\n\n    accuracy                           0.91     12010\n   macro avg       0.91      0.89      0.90     12010\nweighted avg       0.91      0.91      0.91     12010\n\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"import os\nimport time\nimport numpy as np\nfrom sklearn.metrics import f1_score, accuracy_score\n\n# 1. Evaluate Base Model (Float32)\nstart_base = time.time()\nbase_probs = base_model.predict(X_test_loaded, verbose=0)\nbase_preds = (base_probs > 0.5).astype(int)\nbase_time = (time.time() - start_base) / len(X_test_loaded)\nbase_f1 = f1_score(y_test_loaded, base_preds)\n\n# 2. Evaluate Quantized Model (Int8) - Using a sample of 100 for speed\ninterpreter = tf.lite.Interpreter(model_path='/kaggle/working/dos_model_full_int.tflite')\ninterpreter.allocate_tensors()\ninput_details = interpreter.get_input_details()[0]\noutput_details = interpreter.get_output_details()[0]\nin_scale, in_zero = input_details['quantization']\nout_scale, out_zero = output_details['quantization']\n\nq_preds = []\nstart_q = time.time()\nfor i in range(len(X_test_loaded)):\n    input_data = ((X_test_loaded[i] / in_scale) + in_zero).astype(np.uint8)\n    interpreter.set_tensor(input_details['index'], np.expand_dims(input_data, axis=0))\n    interpreter.invoke()\n    output_data = interpreter.get_tensor(output_details['index'])\n    prob = (output_data.astype(np.float32) - out_zero) * out_scale\n    q_preds.append(1 if prob[0][0] > 0.5 else 0)\nq_time = (time.time() - start_q) / len(X_test_loaded)\nq_f1 = f1_score(y_test_loaded, q_preds)\n\n# 3. Model Sizes\nbase_size = os.path.getsize('/kaggle/input/x-test-npy/final_dos_attack_model.keras') / 1024\nq_size = os.path.getsize('/kaggle/working/dos_model_full_int.tflite') / 1024\n\nprint(\"\\n\" + \"=\"*40)\nprint(f\"{'Metric':<20} | {'Base (FP32)':<12} | {'Int8':<10}\")\nprint(\"-\" * 40)\nprint(f\"{'Model Size (KB)':<20} | {base_size:<12.2f} | {q_size:<10.2f}\")\nprint(f\"{'F1-Score (Attack)':<20} | {base_f1:<12.4f} | {q_f1:<10.4f}\")\nprint(f\"{'Latency/Msg (ms)':<20} | {base_time*1000:<12.4f} | {q_time*1000:<10.4f}\")\nprint(\"=\"*40)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T17:01:24.973834Z","iopub.execute_input":"2025-12-31T17:01:24.974312Z","iopub.status.idle":"2025-12-31T17:01:27.365316Z","shell.execute_reply.started":"2025-12-31T17:01:24.974278Z","shell.execute_reply":"2025-12-31T17:01:27.364492Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n    for details.\n    \n  warnings.warn(_INTERPRETER_DELETION_WARNING)\n","output_type":"stream"},{"name":"stdout","text":"\n========================================\nMetric               | Base (FP32)  | Int8      \n----------------------------------------\nModel Size (KB)      | 431.98       | 125.66    \nF1-Score (Attack)    | 0.8614       | 0.8608    \nLatency/Msg (ms)     | 0.1284       | 0.0685    \n========================================\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, f1_score\n\n# 1. Base Model Calculations\nbase_precision = precision_score(y_test_loaded, base_preds)\nbase_recall = recall_score(y_test_loaded, base_preds)\n\n# 2. Int8 Model Calculations (Using q_preds from the previous step)\nq_precision = precision_score(y_test_loaded, q_preds)\nq_recall = recall_score(y_test_loaded, q_preds)\n\n# 3. Print Comparison Table\nprint(\"\\n\" + \"=\"*50)\nprint(f\"{'Metric (DoS Class)':<20} | {'Base (FP32)':<12} | {'Int8 (INT8)':<10}\")\nprint(\"-\" * 50)\nprint(f\"{'Precision':<20} | {base_precision:<12.4f} | {q_precision:<10.4f}\")\nprint(f\"{'Recall':<20} | {base_recall:<12.4f} | {q_recall:<10.4f}\")\nprint(f\"{'F1-Score':<20} | {base_f1:<12.4f} | {q_f1:<10.4f}\")\nprint(\"=\"*50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T17:02:37.822421Z","iopub.execute_input":"2025-12-31T17:02:37.822785Z","iopub.status.idle":"2025-12-31T17:02:37.855040Z","shell.execute_reply.started":"2025-12-31T17:02:37.822757Z","shell.execute_reply":"2025-12-31T17:02:37.854199Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\nMetric (DoS Class)   | Base (FP32)  | Int8 (INT8)\n--------------------------------------------------\nPrecision            | 0.9046       | 0.9045    \nRecall               | 0.8221       | 0.8211    \nF1-Score             | 0.8614       | 0.8608    \n==================================================\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\n\n# 1. Load the actual data (must be loaded as arrays, not strings)\nX_test_data = np.load('/kaggle/working/X_test2.npy')\ny_test_data = np.load('/kaggle/working/y_test2.npy')\n\n# 2. Load the Keras model\n# Note: Ensure the path points to your .keras file\nmodel = tf.keras.models.load_model('/kaggle/input/x-test-npy/final_dos_attack_model.keras')\n\n# 3. Evaluate\nprint(\"Evaluating Baseline Keras Model...\")\nloss, accuracy = model.evaluate(X_test_data, y_test_data, verbose=0)\n\nprint(f\"\\nBaseline Accuracy: {accuracy * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T16:53:36.269806Z","iopub.execute_input":"2025-12-31T16:53:36.270154Z","iopub.status.idle":"2025-12-31T16:53:38.947614Z","shell.execute_reply.started":"2025-12-31T16:53:36.270125Z","shell.execute_reply":"2025-12-31T16:53:38.946634Z"}},"outputs":[{"name":"stdout","text":"Evaluating Baseline Keras Model...\n\nBaseline Accuracy: 91.16%\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"model = tf.keras.Sequential([\n    # Define static batch size (1) for LSTM stability in LiteRT\n    tf.keras.layers.InputLayer(input_shape=(10, 10), batch_size=1),\n    \n    tf.keras.layers.LSTM(64, return_sequences=True),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.LSTM(32),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Dense(16, activation='relu'),\n    tf.keras.layers.Dense(1)\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T14:35:32.671653Z","iopub.execute_input":"2025-12-31T14:35:32.671901Z","iopub.status.idle":"2025-12-31T14:35:32.730218Z","shell.execute_reply.started":"2025-12-31T14:35:32.671885Z","shell.execute_reply":"2025-12-31T14:35:32.728847Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T14:33:44.565719Z","iopub.execute_input":"2025-12-31T14:33:44.566003Z","iopub.status.idle":"2025-12-31T14:33:44.586891Z","shell.execute_reply.started":"2025-12-31T14:33:44.565986Z","shell.execute_reply":"2025-12-31T14:33:44.586023Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m19,200\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">19,200</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m97,253\u001b[0m (379.90 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">97,253</span> (379.90 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m32,353\u001b[0m (126.38 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32,353</span> (126.38 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m192\u001b[0m (768.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> (768.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m64,708\u001b[0m (252.77 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">64,708</span> (252.77 KB)\n</pre>\n"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\n# 1. Load and Preprocess Dataset\ndf = pd.read_csv('/kaggle/input/os-hard-mode-iso-csv/dos_hard_mode_iso.csv')\nfeatures = ['ID_int', 'DLC0', 'DLC1', 'DLC2', 'DLC3', 'DLC4', 'DLC5', 'DLC6', 'DLC7', 'Delta_T']\nX = df[features].values\ny = df['Label'].values\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Create sequences for LSTM\ndef create_sequences(data, labels, window_size=10):\n    X_seq, y_seq = [], []\n    for i in range(len(data) - window_size):\n        X_seq.append(data[i:i + window_size])\n        y_seq.append(labels[i + window_size])\n    return np.array(X_seq), np.array(y_seq)\n\nX_seq, y_seq = create_sequences(X_scaled, y, window_size=10)\nX_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n\n# 2. Define LSTM Model\nmodel = Sequential([\n    LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True),\n    BatchNormalization(),\n    Dropout(0.2),\n    LSTM(32),\n    BatchNormalization(),\n    Dropout(0.2),\n    Dense(16, activation='relu'),\n    Dense(1, activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# 3. Setup Callbacks to save in .keras format\n# This saves the model automatically if validation loss improves\ncheckpoint = ModelCheckpoint(\n    'best_dos_model.keras', \n    monitor='val_loss', \n    save_best_only=True, \n    verbose=1\n)\n\nearly_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n# 4. Train the Model\nmodel.fit(\n    X_train, y_train,\n    epochs=20,\n    batch_size=64,\n    validation_data=(X_test, y_test),\n    callbacks=[checkpoint, early_stop]\n)\n\n# 5. Explicitly save the final model\nmodel.save('final_dos_attack_mode4l243.keras')\n\nprint(\"Model saved as new.keras successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T15:37:48.215736Z","iopub.execute_input":"2025-12-31T15:37:48.216015Z","iopub.status.idle":"2025-12-31T15:40:48.170343Z","shell.execute_reply.started":"2025-12-31T15:37:48.215998Z","shell.execute_reply":"2025-12-31T15:40:48.169732Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"2025-12-31 15:37:48.404338: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(**kwargs)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m750/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8722 - loss: 0.3213\nEpoch 1: val_loss improved from inf to 0.23241, saving model to best_dos_model.keras\n\u001b[1m751/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 15ms/step - accuracy: 0.8723 - loss: 0.3212 - val_accuracy: 0.9107 - val_loss: 0.2324\nEpoch 2/20\n\u001b[1m748/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9101 - loss: 0.2363\nEpoch 2: val_loss improved from 0.23241 to 0.23037, saving model to best_dos_model.keras\n\u001b[1m751/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9101 - loss: 0.2363 - val_accuracy: 0.9112 - val_loss: 0.2304\nEpoch 3/20\n\u001b[1m747/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9109 - loss: 0.2312\nEpoch 3: val_loss improved from 0.23037 to 0.22823, saving model to best_dos_model.keras\n\u001b[1m751/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9109 - loss: 0.2313 - val_accuracy: 0.9116 - val_loss: 0.2282\nEpoch 4/20\n\u001b[1m751/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9107 - loss: 0.2300\nEpoch 4: val_loss did not improve from 0.22823\n\u001b[1m751/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9107 - loss: 0.2300 - val_accuracy: 0.9106 - val_loss: 0.2287\nEpoch 5/20\n\u001b[1m749/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9097 - loss: 0.2307\nEpoch 5: val_loss improved from 0.22823 to 0.22738, saving model to best_dos_model.keras\n\u001b[1m751/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9097 - loss: 0.2307 - val_accuracy: 0.9116 - val_loss: 0.2274\nEpoch 6/20\n\u001b[1m749/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9094 - loss: 0.2334\nEpoch 6: val_loss improved from 0.22738 to 0.22721, saving model to best_dos_model.keras\n\u001b[1m751/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9094 - loss: 0.2334 - val_accuracy: 0.9115 - val_loss: 0.2272\nEpoch 7/20\n\u001b[1m749/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9146 - loss: 0.2254\nEpoch 7: val_loss did not improve from 0.22721\n\u001b[1m751/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9146 - loss: 0.2254 - val_accuracy: 0.9116 - val_loss: 0.2279\nEpoch 8/20\n\u001b[1m748/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9103 - loss: 0.2311\nEpoch 8: val_loss did not improve from 0.22721\n\u001b[1m751/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9103 - loss: 0.2310 - val_accuracy: 0.9110 - val_loss: 0.2290\nEpoch 9/20\n\u001b[1m749/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9092 - loss: 0.2304\nEpoch 9: val_loss did not improve from 0.22721\n\u001b[1m751/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9092 - loss: 0.2304 - val_accuracy: 0.9113 - val_loss: 0.2281\nEpoch 10/20\n\u001b[1m749/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9122 - loss: 0.2275\nEpoch 10: val_loss did not improve from 0.22721\n\u001b[1m751/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9122 - loss: 0.2275 - val_accuracy: 0.9114 - val_loss: 0.2279\nEpoch 11/20\n\u001b[1m751/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9112 - loss: 0.2294\nEpoch 11: val_loss improved from 0.22721 to 0.22686, saving model to best_dos_model.keras\n\u001b[1m751/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9112 - loss: 0.2294 - val_accuracy: 0.9114 - val_loss: 0.2269\nEpoch 12/20\n\u001b[1m748/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9106 - loss: 0.2286\nEpoch 12: val_loss did not improve from 0.22686\n\u001b[1m751/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9106 - loss: 0.2286 - val_accuracy: 0.9108 - val_loss: 0.2300\nEpoch 13/20\n\u001b[1m747/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9110 - loss: 0.2279\nEpoch 13: val_loss did not improve from 0.22686\n\u001b[1m751/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9110 - loss: 0.2279 - val_accuracy: 0.9115 - val_loss: 0.2273\nEpoch 14/20\n\u001b[1m750/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9106 - loss: 0.2271\nEpoch 14: val_loss did not improve from 0.22686\n\u001b[1m751/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9106 - loss: 0.2271 - val_accuracy: 0.9113 - val_loss: 0.2281\nEpoch 15/20\n\u001b[1m751/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9127 - loss: 0.2260\nEpoch 15: val_loss did not improve from 0.22686\n\u001b[1m751/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9127 - loss: 0.2260 - val_accuracy: 0.9117 - val_loss: 0.2273\nEpoch 16/20\n\u001b[1m750/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9104 - loss: 0.2295\nEpoch 16: val_loss did not improve from 0.22686\n\u001b[1m751/751\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9104 - loss: 0.2295 - val_accuracy: 0.9112 - val_loss: 0.2281\nModel saved as new.keras successfully!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport pickle\nimport gc\nimport os\n\n# 1. Re-generate the data (to ensure X_train.npy is healthy)\n# Use your original dataframe and scaler logic here\n# Assuming X_train, X_test, etc., are in memory. If not, re-run your split code first.\n\nprint(\"Saving fresh data files...\")\nnp.save('X_train_fixed.npy', X_train)\n\n# 2. Clear RAM\ntf.keras.backend.clear_session()\ngc.collect()\n\n# 3. Build the TFLite-compatible Static Model\nmodel_static = tf.keras.Sequential([\n    tf.keras.layers.InputLayer(input_shape=(10, 10), batch_size=1),\n    # unroll=True is MANDATORY for full integer quantization of LSTMs\n    tf.keras.layers.LSTM(64, return_sequences=True, unroll=True),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.LSTM(32, unroll=True),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(16, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T15:41:41.471722Z","iopub.execute_input":"2025-12-31T15:41:41.472019Z","iopub.status.idle":"2025-12-31T15:41:42.169558Z","shell.execute_reply.started":"2025-12-31T15:41:41.472001Z","shell.execute_reply":"2025-12-31T15:41:42.168568Z"}},"outputs":[{"name":"stdout","text":"Saving fresh data files...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# 4. Load weights from your trained model\n# Replace 'final_dos_attack_model.keras' with your saved model path\ntrained_model = tf.keras.models.load_model('final_dos_attack_model.keras')\nmodel_static.set_weights(trained_model.get_weights())\ndel trained_model\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T15:42:12.080080Z","iopub.execute_input":"2025-12-31T15:42:12.080408Z","iopub.status.idle":"2025-12-31T15:42:12.576403Z","shell.execute_reply.started":"2025-12-31T15:42:12.080354Z","shell.execute_reply":"2025-12-31T15:42:12.575572Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"4156"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# 5. Calibration Generator (using only 50 samples to save RAM)\ndef representative_data_gen():\n    # Load just a tiny slice\n    data = np.load('X_train_fixed.npy', mmap_mode='r')\n    for i in range(50):\n        sample = np.expand_dims(data[i], axis=0).astype(np.float32)\n        yield [sample]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T15:42:29.317038Z","iopub.execute_input":"2025-12-31T15:42:29.317308Z","iopub.status.idle":"2025-12-31T15:42:29.322634Z","shell.execute_reply.started":"2025-12-31T15:42:29.317291Z","shell.execute_reply":"2025-12-31T15:42:29.321449Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# 6. Convert\nconverter = tf.lite.TFLiteConverter.from_keras_model(model_static)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\nconverter.representative_dataset = representative_data_gen","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T15:42:44.180891Z","iopub.execute_input":"2025-12-31T15:42:44.181139Z","iopub.status.idle":"2025-12-31T15:42:44.186455Z","shell.execute_reply.started":"2025-12-31T15:42:44.181125Z","shell.execute_reply":"2025-12-31T15:42:44.185016Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Set flags for Integer Quantization\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\nconverter.inference_input_type = tf.uint8\nconverter.inference_output_type = tf.uint8","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T15:43:01.173259Z","iopub.execute_input":"2025-12-31T15:43:01.173945Z","iopub.status.idle":"2025-12-31T15:43:01.178596Z","shell.execute_reply.started":"2025-12-31T15:43:01.173922Z","shell.execute_reply":"2025-12-31T15:43:01.177818Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"print(\"Starting conversion... this should be stable now.\")\ntflite_model = converter.convert()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T15:43:21.199027Z","iopub.execute_input":"2025-12-31T15:43:21.199299Z","iopub.status.idle":"2025-12-31T15:43:22.852632Z","shell.execute_reply.started":"2025-12-31T15:43:21.199282Z","shell.execute_reply":"2025-12-31T15:43:22.851877Z"}},"outputs":[{"name":"stdout","text":"Starting conversion... this should be stable now.\nINFO:tensorflow:Assets written to: /tmp/tmpvysqvfxn/assets\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Assets written to: /tmp/tmpvysqvfxn/assets\n","output_type":"stream"},{"name":"stdout","text":"Saved artifact at '/tmp/tmpvysqvfxn'. The following endpoints are available:\n\n* Endpoint 'serve'\n  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 10, 10), dtype=tf.float32, name='keras_tensor')\nOutput Type:\n  TensorSpec(shape=(1, 1), dtype=tf.float32, name=None)\nCaptures:\n  139589351791056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  139589351786640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  139589351787600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  139589351787792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  139589351787408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  139589351787024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  139589351790864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  139589376891152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  139589376893072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  139589351789520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  139589351790096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  139589353442384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  139589351790672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  139589351788944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  139589353441232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  139589353439504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  139589353441424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  139589353440464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/convert.py:997: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n  warnings.warn(\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nW0000 00:00:1767195802.309278    2160 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\nW0000 00:00:1767195802.309333    2160 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\nI0000 00:00:1767195802.325812    2160 mlir_graph_optimization_pass.cc:401] MLIR V1 optimization pass is not enabled\nfully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"with open('dos_model_full_int.tflite', 'wb') as f:\n    f.write(tflite_model)\n\nprint(\"✅ Done! File saved as dos_model_full_int.tflite\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T15:43:43.613489Z","iopub.execute_input":"2025-12-31T15:43:43.613816Z","iopub.status.idle":"2025-12-31T15:43:43.621905Z","shell.execute_reply.started":"2025-12-31T15:43:43.613796Z","shell.execute_reply":"2025-12-31T15:43:43.620530Z"}},"outputs":[{"name":"stdout","text":"✅ Done! File saved as dos_model_full_int.tflite\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport pickle\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom IPython.display import FileLink\n\n# 1. Load the data (Ensure the path is correct for your environment)\ndf = pd.read_csv('/kaggle/input/os-hard-mode-iso-csv/dos_hard_mode_iso.csv')\nfeatures = ['ID_int', 'DLC0', 'DLC1', 'DLC2', 'DLC3', 'DLC4', 'DLC5', 'DLC6', 'DLC7', 'Delta_T']\nX = df[features].values\ny = df['Label'].values\n\n# 2. Scale and SAVE the scaler as a .pkl file\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\nwith open('scaler2.pkl', 'wb') as f:\n    pickle.dump(scaler, f)\n\n# 3. Create sequences\ndef create_sequences(data, labels, window_size=10):\n    X_seq, y_seq = [], []\n    for i in range(len(data) - window_size):\n        X_seq.append(data[i:i + window_size])\n        y_seq.append(labels[i + window_size])\n    return np.array(X_seq), np.array(y_seq)\n\nX_seq, y_seq = create_sequences(X_scaled, y, window_size=10)\n\n# 4. Split the data\nX_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n\n# 5. Save everything to disk\nnp.save('X_train2.npy', X_train)\nnp.save('y_train3.npy', y_train)\nnp.save('X_test2.npy', X_test)\nnp.save('y_test2.npy', y_test)\n\nprint(\"Files saved: X_train.npy, y_train.npy, X_test.npy, y_test.npy, scaler.pkl\")\n\n# 6. Generate download links\ndisplay(FileLink('X_train2.npy'))\ndisplay(FileLink('y_train3.npy'))\ndisplay(FileLink('X_test2.npy'))\ndisplay(FileLink('y_test2.npy'))\ndisplay(FileLink('scaler2.pkl'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T16:37:44.243901Z","iopub.execute_input":"2025-12-31T16:37:44.244265Z","iopub.status.idle":"2025-12-31T16:37:44.617304Z","shell.execute_reply.started":"2025-12-31T16:37:44.244234Z","shell.execute_reply":"2025-12-31T16:37:44.616364Z"}},"outputs":[{"name":"stdout","text":"Files saved: X_train.npy, y_train.npy, X_test.npy, y_test.npy, scaler.pkl\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/X_train2.npy","text/html":"<a href='X_train2.npy' target='_blank'>X_train2.npy</a><br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/y_train3.npy","text/html":"<a href='y_train3.npy' target='_blank'>y_train3.npy</a><br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/X_test2.npy","text/html":"<a href='X_test2.npy' target='_blank'>X_test2.npy</a><br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/y_test2.npy","text/html":"<a href='y_test2.npy' target='_blank'>y_test2.npy</a><br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/scaler2.pkl","text/html":"<a href='scaler2.pkl' target='_blank'>scaler2.pkl</a><br>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\n\n# 1. LOAD your existing trained model first\n# Replace 'final_dos_attack_model.keras' with your actual filename if different\nmodel = tf.keras.models.load_model('/kaggle/input/x-test-npy/final_dos_attack_model.keras')\n\n# 2. Rebuild the model with a static batch size (Exactly as before)\nmodel_static = tf.keras.Sequential([\n    tf.keras.layers.InputLayer(input_shape=(10, 10), batch_size=1),\n    tf.keras.layers.LSTM(64, return_sequences=True),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.LSTM(32),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(16, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\n# 3. NOW copy the weights (this will work because 'model' is an object now)\nmodel_static.set_weights(model.get_weights())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T16:37:52.996670Z","iopub.execute_input":"2025-12-31T16:37:52.996989Z","iopub.status.idle":"2025-12-31T16:37:53.382690Z","shell.execute_reply.started":"2025-12-31T16:37:52.996963Z","shell.execute_reply":"2025-12-31T16:37:53.381646Z"}},"outputs":[{"name":"stderr","text":"2025-12-31 16:37:53.013214: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport gc\n\n# 1. Clear memory from previous attempts\ntf.keras.backend.clear_session()\ngc.collect()\n\n# 2. Load data using mmap (doesn't pull the whole file into RAM)\n# This prevents the kernel from dying immediately\ncalibration_data = np.load('/kaggle/input/x-test-npy/X_train (1).npy', mmap_mode='r')\n\n# 3. Use a very small generator\ndef representative_data_gen():\n    # Reducing to 50 samples can save RAM while still giving good calibration\n    for i in range(50):\n        # Read one sample at a time\n        sample = calibration_data[i].copy() \n        sample = np.expand_dims(sample, axis=0).astype(np.float32)\n        yield [sample]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T16:38:00.526826Z","iopub.execute_input":"2025-12-31T16:38:00.527164Z","iopub.status.idle":"2025-12-31T16:38:00.900035Z","shell.execute_reply.started":"2025-12-31T16:38:00.527137Z","shell.execute_reply":"2025-12-31T16:38:00.899062Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# 4. Configure converter\n# Make sure model_static is defined right before this\nconverter = tf.lite.TFLiteConverter.from_keras_model(model_static)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\nconverter.representative_dataset = representative_data_gen","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T16:38:02.874570Z","iopub.execute_input":"2025-12-31T16:38:02.874927Z","iopub.status.idle":"2025-12-31T16:38:02.880761Z","shell.execute_reply.started":"2025-12-31T16:38:02.874898Z","shell.execute_reply":"2025-12-31T16:38:02.879738Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Mandatory for LSTMs\nconverter.experimental_enable_resource_variables = True\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\nconverter.inference_input_type = tf.uint8\nconverter.inference_output_type = tf.uint8","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T16:38:04.778840Z","iopub.execute_input":"2025-12-31T16:38:04.779184Z","iopub.status.idle":"2025-12-31T16:38:04.784679Z","shell.execute_reply.started":"2025-12-31T16:38:04.779144Z","shell.execute_reply":"2025-12-31T16:38:04.783491Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"\n\nimport numpy as np\nimport tensorflow as tf\nimport pickle\nimport gc\nimport os\n\n# 1. Re-generate the data (to ensure X_train.npy is healthy)\n# Use your original dataframe and scaler logic here\n# Assuming X_train, X_test, etc., are in memory. If not, re-run your split code first.\nX_train='/kaggle/input/x-test-npy/X_train (1).npy'\nprint(\"Saving fresh data files...\")\nnp.save('X_train_fixed.npy', X_train)\n\n# 2. Clear RAM\ntf.keras.backend.clear_session()\ngc.collect()\n\n# 3. Build the TFLite-compatible Static Model\nmodel_static = tf.keras.Sequential([\n    tf.keras.layers.InputLayer(input_shape=(10, 10), batch_size=1),\n    # unroll=True is MANDATORY for full integer quantization of LSTMs\n    tf.keras.layers.LSTM(64, return_sequences=True, unroll=True),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.LSTM(32, unroll=True),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(16, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\n# 4. Load weights from your trained model\n# Replace 'final_dos_attack_model.keras' with your saved model path\ntrained_model = tf.keras.models.load_model('/kaggle/input/x-test-npy/final_dos_attack_model.keras')\nmodel_static.set_weights(trained_model.get_weights())\ndel trained_model\ngc.collect()\n\n# 5. Calibration Generator (using only 50 samples to save RAM)\ndef representative_data_gen():\n    # Load just a tiny slice\n    data = np.load('X_train_fixed.npy', mmap_mode='r')\n    for i in range(50):\n        sample = np.expand_dims(data[i], axis=0).astype(np.float32)\n        yield [sample]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T16:34:50.811436Z","iopub.execute_input":"2025-12-31T16:34:50.812259Z","iopub.status.idle":"2025-12-31T16:34:51.681740Z","shell.execute_reply.started":"2025-12-31T16:34:50.812222Z","shell.execute_reply":"2025-12-31T16:34:51.680910Z"}},"outputs":[{"name":"stdout","text":"Saving fresh data files...\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"tflite_model = converter.convert()\nwith open('dos_model_full_int.tflite', 'wb') as f:\n    f.write(tflite_model)\n\nprint(\"Full Integer Quantized model saved successfully!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3. Define the Representative Dataset Generator\ndef representative_data_gen():\n    # Use 100 samples from X_train to calibrate ranges\n    for input_value in tf.data.Dataset.from_tensor_slices(X_train).batch(1).take(100):\n        yield [tf.cast(input_value, tf.float32)]\n\n# 4. Setup the Converter for Full Integer\nconverter = tf.lite.TFLiteConverter.from_keras_model(model_static)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\nconverter.representative_dataset = representative_data_gen\n\n# Ensure the converter handles the LSTM internals correctly\nconverter.experimental_enable_resource_variables = True\n\n# Force everything to Int8 (No float fallback)\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\nconverter.inference_input_type = tf.uint8\nconverter.inference_output_type = tf.uint8\n\n# 5. Convert and Save\ntflite_full_int_model = converter.convert()\n\nwith open('dos_model_full_int.tflite', 'wb') as f:\n    f.write(tflite_full_int_model)\n\nprint(\"Success! Full Integer Quantized model saved as dos_model_full_int.tflite\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T15:04:16.537914Z","iopub.execute_input":"2025-12-31T15:04:16.538191Z","execution_failed":"2025-12-31T15:04:14.691Z"}},"outputs":[{"name":"stdout","text":"INFO:tensorflow:Assets written to: /tmp/tmpi6r7d7ac/assets\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Assets written to: /tmp/tmpi6r7d7ac/assets\n","output_type":"stream"},{"name":"stdout","text":"Saved artifact at '/tmp/tmpi6r7d7ac'. The following endpoints are available:\n\n* Endpoint 'serve'\n  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 10, 10), dtype=tf.float32, name='keras_tensor_81')\nOutput Type:\n  TensorSpec(shape=(1, 1), dtype=tf.float32, name=None)\nCaptures:\n  133814004537808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  133814004546064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  133813617180944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  133814004545872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  133813609522832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  133814004545296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  133813617181136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  133814004544528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  133814004546256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  133813615385424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  133813615389648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  133813615385808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  133813615384848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  133813615383120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  133813615383696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  133813615383312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  133813615382160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  133813615388880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/tensorflow/lite/python/convert.py:997: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n  warnings.warn(\nW0000 00:00:1767193457.261243    1305 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\nW0000 00:00:1767193457.261268    1305 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# 4. Proceed with conversion...\ndef representative_data_gen():\n    for i in range(100):\n        # We use X_train here (ensure it is loaded in your environment)\n        sample = np.expand_dims(X_train[i], axis=0).astype(np.float32)\n        yield [sample]\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T15:04:36.694515Z","iopub.execute_input":"2025-12-31T15:04:36.694816Z","iopub.status.idle":"2025-12-31T15:04:36.703221Z","shell.execute_reply.started":"2025-12-31T15:04:36.694798Z","shell.execute_reply":"2025-12-31T15:04:36.701912Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"converter = tf.lite.TFLiteConverter.from_keras_model(model)\n\ntflite_model = converter.convert()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"converter = tf.lite.TFLiteConverter.from_keras_model(model)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\nconverter.representative_dataset = representative_data_gen\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T14:48:29.633280Z","iopub.execute_input":"2025-12-31T14:48:29.633579Z","iopub.status.idle":"2025-12-31T14:48:29.637869Z","shell.execute_reply.started":"2025-12-31T14:48:29.633562Z","shell.execute_reply":"2025-12-31T14:48:29.636992Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import tensorflow as tf\n\n# Create the converter from your existing trained model\nconverter_drq = tf.lite.TFLiteConverter.from_keras_model(model)\n\n# 1. Enable Dynamic Range Quantization\nconverter_drq.optimizations = [tf.lite.Optimize.DEFAULT]\n\n# 2. Allow LiteRT to use original TF kernels for the LSTM's TensorLists\nconverter_drq.target_spec.supported_ops = [\n    tf.lite.OpsSet.TFLITE_BUILTINS, # Use TFLite ops where possible\n    tf.lite.OpsSet.SELECT_TF_OPS    # Use TF ops for the failing LSTM parts\n]\n\n# 3. Essential flags for LSTM/Resource Variables\nconverter_drq.experimental_enable_resource_variables = True\nconverter_drq._experimental_lower_tensor_list_ops = False\n\n# 4. Convert\ntflite_drq_model = converter_drq.convert()\n\n# 5. Save the baseline model\nwith open('dos_model_drq_flex.tflite', 'wb') as f:\n    f.write(tflite_drq_model)\n\nprint(\"Success! DRQ Model (with Flex Ops) saved as dos_model_drq_flex.tflite\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T14:54:03.009194Z","iopub.execute_input":"2025-12-31T14:54:03.009559Z","iopub.status.idle":"2025-12-31T14:54:04.017505Z","shell.execute_reply.started":"2025-12-31T14:54:03.009535Z","shell.execute_reply":"2025-12-31T14:54:04.016192Z"}},"outputs":[{"name":"stdout","text":"INFO:tensorflow:Assets written to: /tmp/tmpoo188pbc/assets\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Assets written to: /tmp/tmpoo188pbc/assets\n","output_type":"stream"},{"name":"stdout","text":"Saved artifact at '/tmp/tmpoo188pbc'. The following endpoints are available:\n\n* Endpoint 'serve'\n  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 10, 10), dtype=tf.float32, name='keras_tensor')\nOutput Type:\n  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\nCaptures:\n  134984918624272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  134984918624848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  134984918624656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  134984918625424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  134984918626000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  134984918625040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  134984918622928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  134984918627344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  134984918628112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  134984918628688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  134984918626960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  134984918626384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  134984918627920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  134984918627728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  134984918629456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  134984918629072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  134984918630032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  134984918630224: TensorSpec(shape=(), dtype=tf.resource, name=None)\nSuccess! DRQ Model (with Flex Ops) saved as dos_model_drq_flex.tflite\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1767192843.735319     691 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\nW0000 00:00:1767192843.735352     691 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\n\ndef evaluate_drq_model(tflite_path, X_test, y_test):\n    # 1. Load the TFLite model and allocate tensors\n    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n    interpreter.allocate_tensors()\n\n    # 2. Get input and output details\n    input_details = interpreter.get_input_details()[0]\n    output_details = interpreter.get_output_details()[0]\n\n    predictions = []\n    \n    print(f\"Evaluating {tflite_path}...\")\n\n    # 3. Iterate through the test set\n    for i in range(len(X_test)):\n        # Prepare the input: add batch dimension and ensure float32\n        input_data = np.expand_dims(X_test[i], axis=0).astype(np.float32)\n        \n        # Set the tensor\n        interpreter.set_tensor(input_details['index'], input_data)\n        \n        # Run inference\n        interpreter.invoke()\n        \n        # Get the result (sigmoid output)\n        output_data = interpreter.get_tensor(output_details['index'])\n        # Convert sigmoid probability to binary class (0 or 1)\n        pred = 1 if output_data[0][0] > 0.5 else 0\n        predictions.append(pred)\n\n    # 4. Calculate Accuracy\n    predictions = np.array(predictions)\n    accuracy = (np.sum(predictions == y_test) / len(y_test)) * 100\n    return accuracy\n\n# Run the evaluation\ndrq_accuracy = evaluate_drq_model('/kaggle/working/dos_model_drq_flex.tflite', X_test, y_test)\nprint(f\"\\nDRQ Model Accuracy: {drq_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T14:55:19.778740Z","iopub.execute_input":"2025-12-31T14:55:19.779585Z","iopub.status.idle":"2025-12-31T14:55:23.395547Z","shell.execute_reply.started":"2025-12-31T14:55:19.779566Z","shell.execute_reply":"2025-12-31T14:55:23.394755Z"}},"outputs":[{"name":"stdout","text":"Evaluating /kaggle/working/dos_model_drq_flex.tflite...\n","output_type":"stream"},{"name":"stderr","text":"INFO: Created TensorFlow Lite delegate for select TF ops.\nINFO: TfLiteFlexDelegate delegate: 4 nodes delegated out of 23 nodes with 3 partitions.\n\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n","output_type":"stream"},{"name":"stdout","text":"\nDRQ Model Accuracy: 91.15%\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import numpy as np\n\n# 1. LOAD the actual data from the disk\n# Make sure these paths match your saved file names\nprint(\"Loading test data into memory...\")\nX_test_data = np.load('/kaggle/working/X_test2.npy') \ny_test_data = np.load('/kaggle/working/y_test2.npy')\n\nprint(f\"Loaded {len(X_test_data)} samples.\")\n\n# 2. Re-run the evaluation using the DATA, not the path strings\n# (Make sure 'evaluate_tflite_uint8' is defined in your notebook)\ntry:\n    predictions = evaluate_tflite_uint8(\n        '/kaggle/working/dos_model_full_int.tflite', \n        X_test_data, \n        y_test_data\n    )\nexcept Exception as e:\n    print(f\"Evaluation failed: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T16:50:25.416512Z","iopub.execute_input":"2025-12-31T16:50:25.417266Z","iopub.status.idle":"2025-12-31T16:50:26.285611Z","shell.execute_reply.started":"2025-12-31T16:50:25.417166Z","shell.execute_reply":"2025-12-31T16:50:26.284605Z"}},"outputs":[{"name":"stdout","text":"Loading test data into memory...\nLoaded 12010 samples.\nTesting 12010 samples...\n\n--- Final Evaluation ---\nAccuracy: 91.12%\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.91      0.96      0.93      7996\n           1       0.90      0.82      0.86      4014\n\n    accuracy                           0.91     12010\n   macro avg       0.91      0.89      0.90     12010\nweighted avg       0.91      0.91      0.91     12010\n\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import os\n\nkeras_size = os.path.getsize('final_dos_attack_model.keras') / 1024\ntflite_size = os.path.getsize('dos_model_drq_flex.tflite') / 1024\n\nprint(f\"Original Model Size: {keras_size:.2f} KB\")\nprint(f\"DRQ TFLite Size:     {tflite_size:.2f} KB\")\nprint(f\"Compression Ratio:   {keras_size/tflite_size:.2f}x\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T14:55:59.337826Z","iopub.execute_input":"2025-12-31T14:55:59.338076Z","iopub.status.idle":"2025-12-31T14:55:59.343470Z","shell.execute_reply.started":"2025-12-31T14:55:59.338062Z","shell.execute_reply":"2025-12-31T14:55:59.342568Z"}},"outputs":[{"name":"stdout","text":"Original Model Size: 431.98 KB\nDRQ TFLite Size:     63.37 KB\nCompression Ratio:   6.82x\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# 1. Create the sequences from the scaled data\n# window_size=10 creates a 'lookback' of 10 rows for each prediction\nX_seq, y_seq = create_sequences(X_scaled, y, window_size=10)\n\n# 2. Split into training and testing sets\n# X_train: features for training (80%)\n# X_test: features for testing (20%)\n# y_train: labels for training\n# y_test: labels for testing\nX_train, X_test, y_train, y_test = train_test_split(\n    X_seq, y_seq, test_size=0.2, random_state=42\n)\n\n# 3. Verify the data is ready\nprint(f\"X_train shape: {X_train.shape}\") # Should be (Samples, 10, 10)\nprint(f\"y_train shape: {y_train.shape}\") # Should be (Samples,)\nprint(f\"X_test shape:  {X_test.shape}\")\nprint(f\"y_test shape:  {y_test.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T14:41:13.448852Z","iopub.execute_input":"2025-12-31T14:41:13.449135Z","iopub.status.idle":"2025-12-31T14:41:13.533719Z","shell.execute_reply.started":"2025-12-31T14:41:13.449117Z","shell.execute_reply":"2025-12-31T14:41:13.532843Z"}},"outputs":[{"name":"stdout","text":"X_train shape: (48038, 10, 10)\ny_train shape: (48038,)\nX_test shape:  (12010, 10, 10)\ny_test shape:  (12010,)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import tensorflow as tf\n\ndef representative_data_gen():\n    # Use X_train for calibration\n    for input_value in tf.data.Dataset.from_tensor_slices(X_train).batch(1).take(100):\n        # The model expects float32 during calibration\n        yield [tf.cast(input_value, tf.float32)]\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T14:42:17.427680Z","iopub.execute_input":"2025-12-31T14:42:17.427920Z","iopub.status.idle":"2025-12-31T14:42:22.667717Z","shell.execute_reply.started":"2025-12-31T14:42:17.427903Z","shell.execute_reply":"2025-12-31T14:42:22.666164Z"}},"outputs":[{"name":"stderr","text":"2025-12-31 14:42:17.744150: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767192137.760331     691 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767192137.764969     691 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport pickle\nimport gc\nimport os\n\n# 1. Re-generate the data (to ensure X_train.npy is healthy)\n# Use your original dataframe and scaler logic here\n# Assuming X_train, X_test, etc., are in memory. If not, re-run your split code first.\nX_train='/kaggle/working/X_train2.npy'\nprint(\"Saving fresh data files...\")\nnp.save('X_train_fixed.npy', X_train)\n\n# 2. Clear RAM\ntf.keras.backend.clear_session()\ngc.collect()\n\n# 3. Build the TFLite-compatible Static Model\nmodel_static = tf.keras.Sequential([\n    tf.keras.layers.InputLayer(input_shape=(10, 10), batch_size=1),\n    # unroll=True is MANDATORY for full integer quantization of LSTMs\n    tf.keras.layers.LSTM(64, return_sequences=True, unroll=True),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.LSTM(32, unroll=True),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(16, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T16:39:47.884553Z","iopub.execute_input":"2025-12-31T16:39:47.885236Z","iopub.status.idle":"2025-12-31T16:39:52.843376Z","shell.execute_reply.started":"2025-12-31T16:39:47.885203Z","shell.execute_reply":"2025-12-31T16:39:52.842335Z"}},"outputs":[{"name":"stderr","text":"2025-12-31 16:39:48.294859: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1767199188.323117     293 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1767199188.331473     293 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1767199188.354355     293 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767199188.354387     293 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767199188.354392     293 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1767199188.354395     293 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"Saving fresh data files...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n  warnings.warn(\n2025-12-31 16:39:52.725135: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# 4. Load weights from your trained model\n# Replace 'final_dos_attack_model.keras' with your saved model path\ntrained_model = tf.keras.models.load_model('/kaggle/input/x-test-npy/final_dos_attack_model.keras')\nmodel_static.set_weights(trained_model.get_weights())\ndel trained_model\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T16:40:34.094585Z","iopub.execute_input":"2025-12-31T16:40:34.094899Z","iopub.status.idle":"2025-12-31T16:40:34.529512Z","shell.execute_reply.started":"2025-12-31T16:40:34.094869Z","shell.execute_reply":"2025-12-31T16:40:34.528565Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"4111"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# 5. Calibration Generator (using only 50 samples to save RAM)\ndef representative_data_gen():\n    # Load just a tiny slice\n    data = np.load('X_train_fixed.npy', mmap_mode='r')\n    for i in range(50):\n        sample = np.expand_dims(data[i], axis=0).astype(np.float32)\n        yield [sample]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T16:40:46.781042Z","iopub.execute_input":"2025-12-31T16:40:46.781365Z","iopub.status.idle":"2025-12-31T16:40:46.786970Z","shell.execute_reply.started":"2025-12-31T16:40:46.781338Z","shell.execute_reply":"2025-12-31T16:40:46.786028Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"\nconverter = tf.lite.TFLiteConverter.from_keras_model(model_static)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\nconverter.representative_dataset = representative_data_gen","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T16:41:06.162350Z","iopub.execute_input":"2025-12-31T16:41:06.163650Z","iopub.status.idle":"2025-12-31T16:41:06.168341Z","shell.execute_reply.started":"2025-12-31T16:41:06.163607Z","shell.execute_reply":"2025-12-31T16:41:06.167558Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Set flags for Integer Quantization\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\nconverter.inference_input_type = tf.uint8\nconverter.inference_output_type = tf.uint8","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T16:41:16.915453Z","iopub.execute_input":"2025-12-31T16:41:16.916119Z","iopub.status.idle":"2025-12-31T16:41:16.920965Z","shell.execute_reply.started":"2025-12-31T16:41:16.916085Z","shell.execute_reply":"2025-12-31T16:41:16.920145Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport gc\n\n# 1. LOAD the data from the string path into a real array\n# Your error showed X_train was pointing to '/kaggle/working/X_train2.npy'\nprint(\"Loading actual data from disk...\")\npath_to_data = '/kaggle/working/X_train2.npy' # Ensure this matches your file name\nX_train_data = np.load(path_to_data) \n\nprint(f\"Data loaded successfully. Shape: {X_train_data.shape}\")\n\n# 2. Define the generator using the REAL data array\ndef representative_data_gen():\n    for i in range(100):\n        # Slice one sample and ensure it has the batch dimension (1, 10, 10)\n        sample = X_train_data[i:i+1].astype(np.float32)\n        yield [sample]\n\n# 3. Build the Static Model with unroll=True (Required for LSTM Quantization)\nmodel_static = tf.keras.Sequential([\n    tf.keras.layers.InputLayer(input_shape=(10, 10), batch_size=1),\n    tf.keras.layers.LSTM(64, return_sequences=True, unroll=True),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.LSTM(32, unroll=True),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(16, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\n\n# 4. Load weights from your trained model\ntrained_model = tf.keras.models.load_model('/kaggle/input/x-test-npy/final_dos_attack_model.keras')\nmodel_static.set_weights(trained_model.get_weights())\n\n# 5. Setup and Run Converter\nconverter = tf.lite.TFLiteConverter.from_keras_model(model_static)\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\nconverter.representative_dataset = representative_data_gen\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\nconverter.inference_input_type = tf.uint8\nconverter.inference_output_type = tf.uint8\nconverter.experimental_enable_resource_variables = True\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T16:45:53.362543Z","iopub.execute_input":"2025-12-31T16:45:53.362908Z","iopub.status.idle":"2025-12-31T16:45:53.634796Z","shell.execute_reply.started":"2025-12-31T16:45:53.362879Z","shell.execute_reply":"2025-12-31T16:45:53.633619Z"}},"outputs":[{"name":"stdout","text":"Loading actual data from disk...\nData loaded successfully. Shape: (48038, 10, 10)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"print(\"Starting conversion... this should now work.\")\ntflite_model = converter.convert()\n\nwith open('dos_model_full_int.tflite', 'wb') as f:\n    f.write(tflite_model)\n\nprint(\"✅ Success! Full Integer model saved as dos_model_full_int.tflite\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T16:46:19.192147Z","iopub.execute_input":"2025-12-31T16:46:19.193188Z","iopub.status.idle":"2025-12-31T16:46:21.270001Z","shell.execute_reply.started":"2025-12-31T16:46:19.193145Z","shell.execute_reply":"2025-12-31T16:46:21.269002Z"}},"outputs":[{"name":"stdout","text":"Starting conversion... this should now work.\nINFO:tensorflow:Assets written to: /tmp/tmp0tn4426t/assets\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Assets written to: /tmp/tmp0tn4426t/assets\n","output_type":"stream"},{"name":"stdout","text":"Saved artifact at '/tmp/tmp0tn4426t'. The following endpoints are available:\n\n* Endpoint 'serve'\n  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 10, 10), dtype=tf.float32, name='keras_tensor_43')\nOutput Type:\n  TensorSpec(shape=(1, 1), dtype=tf.float32, name=None)\nCaptures:\n  132994875083280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  132994875081936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  132994875084624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  132994875084816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  132994875083856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  132994875084048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  132994875084432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  132994875085200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  132994875085584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  132994875085968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  132994875086160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  132994875085392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  132994875082512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  132994875085776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  132994875086544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  132994875083472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  132994875087312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n  132994875086736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/convert.py:854: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n  warnings.warn(\nW0000 00:00:1767199580.436190     293 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\nW0000 00:00:1767199580.436219     293 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\nfully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: UINT8\n","output_type":"stream"},{"name":"stdout","text":"✅ Success! Full Integer model saved as dos_model_full_int.tflite\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"\"\"\"\nCAN Bus Intrusion Detection System Model Comparison\nCompares FP32 Keras model vs INT8 TFLite quantized model\n\"\"\"\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    confusion_matrix, classification_report, roc_curve, auc,\n    precision_recall_curve, average_precision_score\n)\nimport pandas as pd\nfrom pathlib import Path\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set style for better-looking plots\nplt.style.use('seaborn-v0_8-darkgrid')\nsns.set_palette(\"husl\")\n\n\nclass TFLiteModel:\n    \"\"\"Wrapper for TFLite model with proper quantization handling\"\"\"\n    \n    def __init__(self, model_path):\n        self.interpreter = tf.lite.Interpreter(model_path=str(model_path))\n        self.interpreter.allocate_tensors()\n        \n        # Get input and output details\n        self.input_details = self.interpreter.get_input_details()[0]\n        self.output_details = self.interpreter.get_output_details()[0]\n        \n        # Extract quantization parameters\n        self.input_scale = self.input_details['quantization'][0]\n        self.input_zero_point = self.input_details['quantization'][1]\n        self.output_scale = self.output_details['quantization'][0]\n        self.output_zero_point = self.output_details['quantization'][1]\n        \n        print(f\"TFLite Model Loaded:\")\n        print(f\"  Input shape: {self.input_details['shape']}\")\n        print(f\"  Input dtype: {self.input_details['dtype'].__name__}\")\n        print(f\"  Input scale: {self.input_scale}, zero_point: {self.input_zero_point}\")\n        print(f\"  Output dtype: {self.output_details['dtype'].__name__}\")\n        print(f\"  Output scale: {self.output_scale}, zero_point: {self.output_zero_point}\")\n    \n    def quantize_input(self, x):\n        \"\"\"Quantize float input to appropriate dtype\"\"\"\n        quantized = x / self.input_scale + self.input_zero_point\n        return quantized.astype(self.input_details['dtype'])\n    \n    def dequantize_output(self, y_quantized):\n        \"\"\"Dequantize output back to float\"\"\"\n        # Handle both int8 and uint8\n        if self.output_details['dtype'] == np.uint8:\n            y_float = y_quantized.astype(np.float32)\n        else:\n            y_float = y_quantized.astype(np.float32)\n        return (y_float - self.output_zero_point) * self.output_scale\n    \n    def predict(self, X):\n        \"\"\"Run inference on batch of samples\"\"\"\n        predictions = []\n        \n        for i in range(len(X)):\n            # Quantize input\n            x_quantized = self.quantize_input(X[i:i+1])\n            \n            # Set input tensor\n            self.interpreter.set_tensor(self.input_details['index'], x_quantized)\n            \n            # Run inference\n            self.interpreter.invoke()\n            \n            # Get output tensor\n            output = self.interpreter.get_tensor(self.output_details['index'])\n            \n            # Dequantize output\n            output_float = self.dequantize_output(output)\n            predictions.append(output_float[0])\n        \n        return np.array(predictions)\n\n\nclass ModelComparator:\n    \"\"\"Compare FP32 and INT8 models\"\"\"\n    \n    def __init__(self, keras_path, tflite_path, X_test, y_test):\n        self.X_test = X_test\n        self.y_test = y_test\n        self.output_dir = Path(\"comparison_results\")\n        self.output_dir.mkdir(exist_ok=True)\n        \n        # Load models\n        print(\"Loading FP32 Keras model...\")\n        self.fp32_model = keras.models.load_model(keras_path)\n        print(f\"Model loaded. Input shape: {self.fp32_model.input_shape}\")\n        \n        print(\"\\nLoading INT8 TFLite model...\")\n        self.int8_model = TFLiteModel(tflite_path)\n        \n        # Run inference\n        print(\"\\n\" + \"=\"*70)\n        print(\"Running Inference...\")\n        print(\"=\"*70)\n        self.run_inference()\n        \n        # Compute metrics\n        print(\"\\nComputing metrics...\")\n        self.compute_metrics()\n        \n        # Generate visualizations\n        print(\"\\nGenerating visualizations...\")\n        self.generate_visualizations()\n        \n        # Print comparison table\n        print(\"\\n\" + \"=\"*70)\n        self.print_comparison_table()\n        print(\"=\"*70)\n        \n        print(f\"\\nAll results saved to: {self.output_dir}/\")\n    \n    def run_inference(self):\n        \"\"\"Run inference on both models\"\"\"\n        # FP32 model\n        print(\"Running FP32 Keras inference...\")\n        self.fp32_probs = self.fp32_model.predict(self.X_test, batch_size=128, verbose=1)\n        self.fp32_probs = self.fp32_probs.flatten()\n        self.fp32_preds = (self.fp32_probs >= 0.5).astype(int)\n        \n        # INT8 model\n        print(\"\\nRunning INT8 TFLite inference...\")\n        self.int8_probs = self.int8_model.predict(self.X_test)\n        self.int8_probs = self.int8_probs.flatten()\n        self.int8_preds = (self.int8_probs >= 0.5).astype(int)\n        \n        print(f\"\\nInference complete!\")\n        print(f\"  FP32 predictions shape: {self.fp32_preds.shape}\")\n        print(f\"  INT8 predictions shape: {self.int8_preds.shape}\")\n    \n    def compute_metrics(self):\n        \"\"\"Compute all metrics for both models\"\"\"\n        self.metrics = {}\n        \n        for name, y_pred, y_prob in [\n            ('FP32', self.fp32_preds, self.fp32_probs),\n            ('INT8', self.int8_preds, self.int8_probs)\n        ]:\n            # Confusion matrix\n            tn, fp, fn, tp = confusion_matrix(self.y_test, y_pred).ravel()\n            \n            # Compute metrics\n            acc = accuracy_score(self.y_test, y_pred)\n            prec = precision_score(self.y_test, y_pred, zero_division=0)\n            rec = recall_score(self.y_test, y_pred, zero_division=0)\n            f1 = f1_score(self.y_test, y_pred, zero_division=0)\n            fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n            \n            # ROC and PR AUC\n            fpr_curve, tpr_curve, _ = roc_curve(self.y_test, y_prob)\n            roc_auc = auc(fpr_curve, tpr_curve)\n            pr_auc = average_precision_score(self.y_test, y_prob)\n            \n            self.metrics[name] = {\n                'accuracy': acc,\n                'precision': prec,\n                'recall': rec,\n                'f1_score': f1,\n                'fpr': fpr,\n                'roc_auc': roc_auc,\n                'pr_auc': pr_auc,\n                'confusion_matrix': confusion_matrix(self.y_test, y_pred),\n                'classification_report': classification_report(self.y_test, y_pred)\n            }\n            \n            print(f\"\\n{name} Model Classification Report:\")\n            print(self.metrics[name]['classification_report'])\n    \n    def generate_visualizations(self):\n        \"\"\"Generate all comparison plots\"\"\"\n        self.plot_roc_curves()\n        self.plot_pr_curves()\n        self.plot_confusion_matrices()\n        self.plot_metrics_comparison()\n        self.plot_probability_distributions()\n        print(f\"All plots saved to {self.output_dir}/\")\n    \n    def plot_roc_curves(self):\n        \"\"\"Plot ROC curves for both models\"\"\"\n        plt.figure(figsize=(10, 8))\n        \n        colors = ['#2E86AB', '#A23B72']\n        for (name, y_prob), color in zip(\n            [('FP32', self.fp32_probs), ('INT8', self.int8_probs)],\n            colors\n        ):\n            fpr, tpr, _ = roc_curve(self.y_test, y_prob)\n            roc_auc = self.metrics[name]['roc_auc']\n            plt.plot(fpr, tpr, color=color, lw=2.5, \n                    label=f'{name} (AUC = {roc_auc:.4f})')\n        \n        plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier')\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.05])\n        plt.xlabel('False Positive Rate', fontsize=12, fontweight='bold')\n        plt.ylabel('True Positive Rate', fontsize=12, fontweight='bold')\n        plt.title('ROC Curves: FP32 vs INT8 Models', fontsize=14, fontweight='bold')\n        plt.legend(loc=\"lower right\", fontsize=11)\n        plt.grid(True, alpha=0.3)\n        plt.tight_layout()\n        plt.savefig(self.output_dir / 'roc_curves.png', dpi=300, bbox_inches='tight')\n        plt.close()\n    \n    def plot_pr_curves(self):\n        \"\"\"Plot Precision-Recall curves\"\"\"\n        plt.figure(figsize=(10, 8))\n        \n        colors = ['#2E86AB', '#A23B72']\n        for (name, y_prob), color in zip(\n            [('FP32', self.fp32_probs), ('INT8', self.int8_probs)],\n            colors\n        ):\n            precision, recall, _ = precision_recall_curve(self.y_test, y_prob)\n            pr_auc = self.metrics[name]['pr_auc']\n            plt.plot(recall, precision, color=color, lw=2.5,\n                    label=f'{name} (AP = {pr_auc:.4f})')\n        \n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.05])\n        plt.xlabel('Recall', fontsize=12, fontweight='bold')\n        plt.ylabel('Precision', fontsize=12, fontweight='bold')\n        plt.title('Precision-Recall Curves: FP32 vs INT8 Models', \n                 fontsize=14, fontweight='bold')\n        plt.legend(loc=\"lower left\", fontsize=11)\n        plt.grid(True, alpha=0.3)\n        plt.tight_layout()\n        plt.savefig(self.output_dir / 'pr_curves.png', dpi=300, bbox_inches='tight')\n        plt.close()\n    \n    def plot_confusion_matrices(self):\n        \"\"\"Plot confusion matrices for both models\"\"\"\n        fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n        \n        for idx, (name, ax) in enumerate(zip(['FP32', 'INT8'], axes)):\n            cm = self.metrics[name]['confusion_matrix']\n            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n                       cbar_kws={'label': 'Count'},\n                       annot_kws={'size': 14, 'weight': 'bold'})\n            ax.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')\n            ax.set_ylabel('True Label', fontsize=12, fontweight='bold')\n            ax.set_title(f'{name} Model Confusion Matrix', \n                        fontsize=14, fontweight='bold')\n            ax.set_xticklabels(['Normal (0)', 'Attack (1)'])\n            ax.set_yticklabels(['Normal (0)', 'Attack (1)'])\n        \n        plt.tight_layout()\n        plt.savefig(self.output_dir / 'confusion_matrices.png', \n                   dpi=300, bbox_inches='tight')\n        plt.close()\n    \n    def plot_metrics_comparison(self):\n        \"\"\"Plot bar chart comparing key metrics\"\"\"\n        metrics_to_plot = ['precision', 'recall', 'f1_score', 'fpr']\n        metric_labels = ['Precision', 'Recall', 'F1-Score', 'FPR']\n        \n        fp32_values = [self.metrics['FP32'][m] for m in metrics_to_plot]\n        int8_values = [self.metrics['INT8'][m] for m in metrics_to_plot]\n        \n        x = np.arange(len(metric_labels))\n        width = 0.35\n        \n        fig, ax = plt.subplots(figsize=(12, 7))\n        bars1 = ax.bar(x - width/2, fp32_values, width, label='FP32 Keras',\n                      color='#2E86AB', alpha=0.8)\n        bars2 = ax.bar(x + width/2, int8_values, width, label='INT8 TFLite',\n                      color='#A23B72', alpha=0.8)\n        \n        ax.set_xlabel('Metrics', fontsize=12, fontweight='bold')\n        ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n        ax.set_title('Performance Metrics Comparison: FP32 vs INT8', \n                    fontsize=14, fontweight='bold')\n        ax.set_xticks(x)\n        ax.set_xticklabels(metric_labels)\n        ax.legend(fontsize=11)\n        ax.set_ylim([0, 1.1])\n        ax.grid(True, alpha=0.3, axis='y')\n        \n        # Add value labels on bars\n        def autolabel(bars):\n            for bar in bars:\n                height = bar.get_height()\n                ax.annotate(f'{height:.4f}',\n                          xy=(bar.get_x() + bar.get_width() / 2, height),\n                          xytext=(0, 3),\n                          textcoords=\"offset points\",\n                          ha='center', va='bottom', fontsize=9)\n        \n        autolabel(bars1)\n        autolabel(bars2)\n        \n        plt.tight_layout()\n        plt.savefig(self.output_dir / 'metrics_comparison.png', \n                   dpi=300, bbox_inches='tight')\n        plt.close()\n    \n    def plot_probability_distributions(self):\n        \"\"\"Plot prediction probability distributions\"\"\"\n        fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n        \n        # FP32 distribution\n        axes[0, 0].hist(self.fp32_probs[self.y_test == 0], bins=50, \n                       alpha=0.7, color='blue', label='Normal', edgecolor='black')\n        axes[0, 0].hist(self.fp32_probs[self.y_test == 1], bins=50, \n                       alpha=0.7, color='red', label='Attack', edgecolor='black')\n        axes[0, 0].axvline(0.5, color='black', linestyle='--', linewidth=2, \n                          label='Threshold')\n        axes[0, 0].set_xlabel('Prediction Probability', fontweight='bold')\n        axes[0, 0].set_ylabel('Frequency', fontweight='bold')\n        axes[0, 0].set_title('FP32 Model: Probability Distribution by Class', \n                            fontweight='bold')\n        axes[0, 0].legend()\n        axes[0, 0].grid(True, alpha=0.3)\n        \n        # INT8 distribution\n        axes[0, 1].hist(self.int8_probs[self.y_test == 0], bins=50, \n                       alpha=0.7, color='blue', label='Normal', edgecolor='black')\n        axes[0, 1].hist(self.int8_probs[self.y_test == 1], bins=50, \n                       alpha=0.7, color='red', label='Attack', edgecolor='black')\n        axes[0, 1].axvline(0.5, color='black', linestyle='--', linewidth=2, \n                          label='Threshold')\n        axes[0, 1].set_xlabel('Prediction Probability', fontweight='bold')\n        axes[0, 1].set_ylabel('Frequency', fontweight='bold')\n        axes[0, 1].set_title('INT8 Model: Probability Distribution by Class', \n                            fontweight='bold')\n        axes[0, 1].legend()\n        axes[0, 1].grid(True, alpha=0.3)\n        \n        # Overall comparison\n        axes[1, 0].hist(self.fp32_probs, bins=50, alpha=0.6, \n                       color='#2E86AB', label='FP32', edgecolor='black')\n        axes[1, 0].hist(self.int8_probs, bins=50, alpha=0.6, \n                       color='#A23B72', label='INT8', edgecolor='black')\n        axes[1, 0].axvline(0.5, color='black', linestyle='--', linewidth=2)\n        axes[1, 0].set_xlabel('Prediction Probability', fontweight='bold')\n        axes[1, 0].set_ylabel('Frequency', fontweight='bold')\n        axes[1, 0].set_title('Overall Probability Distribution Comparison', \n                            fontweight='bold')\n        axes[1, 0].legend()\n        axes[1, 0].grid(True, alpha=0.3)\n        \n        # Difference plot\n        prob_diff = self.fp32_probs - self.int8_probs\n        axes[1, 1].hist(prob_diff, bins=50, color='purple', \n                       alpha=0.7, edgecolor='black')\n        axes[1, 1].axvline(0, color='black', linestyle='--', linewidth=2)\n        axes[1, 1].set_xlabel('Probability Difference (FP32 - INT8)', \n                             fontweight='bold')\n        axes[1, 1].set_ylabel('Frequency', fontweight='bold')\n        axes[1, 1].set_title('Prediction Probability Difference Distribution', \n                            fontweight='bold')\n        axes[1, 1].grid(True, alpha=0.3)\n        \n        plt.tight_layout()\n        plt.savefig(self.output_dir / 'probability_distributions.png', \n                   dpi=300, bbox_inches='tight')\n        plt.close()\n    \n    def print_comparison_table(self):\n        \"\"\"Print detailed comparison table\"\"\"\n        print(\"\\n\" + \"=\"*70)\n        print(\"COMPREHENSIVE MODEL COMPARISON\")\n        print(\"=\"*70 + \"\\n\")\n        \n        # Create comparison dataframe\n        metrics_list = ['accuracy', 'precision', 'recall', 'f1_score', 'fpr', \n                       'roc_auc', 'pr_auc']\n        \n        data = []\n        for metric in metrics_list:\n            fp32_val = self.metrics['FP32'][metric]\n            int8_val = self.metrics['INT8'][metric]\n            diff = int8_val - fp32_val\n            pct_change = (diff / fp32_val * 100) if fp32_val != 0 else 0\n            \n            data.append({\n                'Metric': metric.upper().replace('_', ' '),\n                'FP32 Keras': f'{fp32_val:.6f}',\n                'INT8 TFLite': f'{int8_val:.6f}',\n                'Δ Difference': f'{diff:+.6f}',\n                '% Change': f'{pct_change:+.2f}%'\n            })\n        \n        df = pd.DataFrame(data)\n        print(df.to_string(index=False))\n        \n        # Save to CSV\n        df.to_csv(self.output_dir / 'comparison_table.csv', index=False)\n        \n        # Summary statistics\n        print(f\"\\n{'='*70}\")\n        print(\"SUMMARY STATISTICS\")\n        print(f\"{'='*70}\")\n        print(f\"Total test samples: {len(self.y_test)}\")\n        print(f\"Normal samples: {np.sum(self.y_test == 0)} \"\n              f\"({np.sum(self.y_test == 0)/len(self.y_test)*100:.2f}%)\")\n        print(f\"Attack samples: {np.sum(self.y_test == 1)} \"\n              f\"({np.sum(self.y_test == 1)/len(self.y_test)*100:.2f}%)\")\n        \n        print(f\"\\nMean probability difference: \"\n              f\"{np.mean(np.abs(self.fp32_probs - self.int8_probs)):.6f}\")\n        print(f\"Max probability difference: \"\n              f\"{np.max(np.abs(self.fp32_probs - self.int8_probs)):.6f}\")\n        \n        # Prediction agreement\n        agreement = np.sum(self.fp32_preds == self.int8_preds) / len(self.y_test)\n        print(f\"\\nPrediction agreement rate: {agreement:.4f} \"\n              f\"({agreement*100:.2f}%)\")\n        \n        disagreement_indices = np.where(self.fp32_preds != self.int8_preds)[0]\n        print(f\"Disagreement cases: {len(disagreement_indices)}\")\n\n\n# Main execution\nif __name__ == \"__main__\":\n    print(\"=\"*70)\n    print(\"CAN BUS INTRUSION DETECTION SYSTEM - MODEL COMPARISON\")\n    print(\"=\"*70)\n    \n    # Define file paths - UPDATE THESE TO MATCH YOUR FILES\n    KERAS_MODEL_PATH = \"/kaggle/input/x-test-npy/final_dos_attack_model.keras\"  # Your FP32 Keras model\n    TFLITE_MODEL_PATH = \"/kaggle/working/dos_model_full_int.tflite\"  # Your INT8 TFLite model\n    \n    # IMPORTANT: Make sure both paths point to different files!\n    # Example:\n    # KERAS_MODEL_PATH = \"/kaggle/input/models/base_model.keras\"\n    # TFLITE_MODEL_PATH = \"/kaggle/input/models/guardcan_lstm_int8.tflite\"\n    \n    # =====================================================================\n    # LOAD TEST DATA\n    # =====================================================================\n    # Option 1: If X_test and y_test are already in memory as variables\n    try:\n        # Check if they exist in the current namespace\n        if isinstance(X_test, str):\n            # If they're file paths, load them\n            print(f\"\\nLoading test data from files...\")\n            print(f\"  X_test: {X_test}\")\n            print(f\"  y_test: {y_test}\")\n            X_test_data = np.load(X_test)\n            y_test_data = np.load(y_test)\n        else:\n            # Already loaded as arrays\n            X_test_data = X_test\n            y_test_data = y_test\n    except NameError:\n        # Option 2: Load from file paths\n        print(\"\\nX_test and y_test not found in scope. Loading from files...\")\n        X_TEST_PATH = \"/kaggle/working/X_test2.npy\"  # UPDATE THIS PATH\n        Y_TEST_PATH = \"/kaggle/working/y_test2.npy\"  # UPDATE THIS PATH\n        \n        print(f\"  X_test: {X_TEST_PATH}\")\n        print(f\"  y_test: {Y_TEST_PATH}\")\n        \n        X_test_data = np.load(X_TEST_PATH)\n        y_test_data = np.load(Y_TEST_PATH)\n    \n    # Verify data shapes\n    print(f\"\\nTest data loaded successfully:\")\n    print(f\"  X_test shape: {X_test_data.shape}\")\n    print(f\"  y_test shape: {y_test_data.shape}\")\n    print(f\"  Data type: {X_test_data.dtype}\")\n    \n    assert len(X_test_data.shape) == 3, \"X_test must be 3D: (samples, timesteps, features)\"\n    assert X_test_data.shape[1:] == (10, 10), f\"Expected shape (N, 10, 10), got {X_test_data.shape}\"\n    \n    # Run comparison\n    comparator = ModelComparator(\n        keras_path=KERAS_MODEL_PATH,\n        tflite_path=TFLITE_MODEL_PATH,\n        X_test=X_test_data,  # Pass the loaded numpy arrays\n        y_test=y_test_data   # Not the file paths!\n    )\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"ANALYSIS COMPLETE!\")\n    print(\"=\"*70)\n    print(\"\\nConclusion:\")\n    \n    # Automated conclusion\n    acc_diff = (comparator.metrics['INT8']['accuracy'] - \n                comparator.metrics['FP32']['accuracy'])\n    f1_diff = (comparator.metrics['INT8']['f1_score'] - \n               comparator.metrics['FP32']['f1_score'])\n    \n    if abs(acc_diff) < 0.01 and abs(f1_diff) < 0.01:\n        print(\"✓ INT8 quantization has MINIMAL IMPACT on model performance.\")\n        print(\"  The quantized model is suitable for deployment.\")\n    elif acc_diff < -0.05 or f1_diff < -0.05:\n        print(\"⚠ INT8 quantization significantly degrades performance.\")\n        print(\"  Consider alternative quantization strategies or keep FP32.\")\n    else:\n        print(\"→ INT8 quantization shows moderate impact on performance.\")\n        print(\"  Evaluate based on deployment constraints (latency/memory).\")\n    \n    print(f\"\\nAll results saved to: {comparator.output_dir}/\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-31T17:22:20.888251Z","iopub.execute_input":"2025-12-31T17:22:20.889140Z","iopub.status.idle":"2025-12-31T17:22:29.301646Z","shell.execute_reply.started":"2025-12-31T17:22:20.889097Z","shell.execute_reply":"2025-12-31T17:22:29.300537Z"}},"outputs":[{"name":"stdout","text":"======================================================================\nCAN BUS INTRUSION DETECTION SYSTEM - MODEL COMPARISON\n======================================================================\n\nLoading test data from files...\n  X_test: /kaggle/working/X_test2.npy\n  y_test: /kaggle/working/y_test2.npy\n\nTest data loaded successfully:\n  X_test shape: (12010, 10, 10)\n  y_test shape: (12010,)\n  Data type: float64\nLoading FP32 Keras model...\nModel loaded. Input shape: (None, 10, 10)\n\nLoading INT8 TFLite model...\nTFLite Model Loaded:\n  Input shape: [ 1 10 10]\n  Input dtype: uint8\n  Input scale: 0.02018970064818859, zero_point: 102\n  Output dtype: uint8\n  Output scale: 0.00390625, zero_point: 0\n\n======================================================================\nRunning Inference...\n======================================================================\nRunning FP32 Keras inference...\n\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n\nRunning INT8 TFLite inference...\n\nInference complete!\n  FP32 predictions shape: (12010,)\n  INT8 predictions shape: (12010,)\n\nComputing metrics...\n\nFP32 Model Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.91      0.96      0.94      7996\n           1       0.90      0.82      0.86      4014\n\n    accuracy                           0.91     12010\n   macro avg       0.91      0.89      0.90     12010\nweighted avg       0.91      0.91      0.91     12010\n\n\nINT8 Model Classification Report:\n              precision    recall  f1-score   support\n\n           0       0.91      0.96      0.94      7996\n           1       0.90      0.82      0.86      4014\n\n    accuracy                           0.91     12010\n   macro avg       0.91      0.89      0.90     12010\nweighted avg       0.91      0.91      0.91     12010\n\n\nGenerating visualizations...\nAll plots saved to comparison_results/\n\n======================================================================\n\n======================================================================\nCOMPREHENSIVE MODEL COMPARISON\n======================================================================\n\n   Metric FP32 Keras INT8 TFLite Δ Difference % Change\n ACCURACY   0.911574    0.911490    -0.000083   -0.01%\nPRECISION   0.904605    0.904579    -0.000026   -0.00%\n   RECALL   0.822123    0.821873    -0.000249   -0.03%\n F1 SCORE   0.861394    0.861245    -0.000149   -0.02%\n      FPR   0.043522    0.043522    +0.000000   +0.00%\n  ROC AUC   0.955728    0.954785    -0.000942   -0.10%\n   PR AUC   0.920453    0.908421    -0.012033   -1.31%\n\n======================================================================\nSUMMARY STATISTICS\n======================================================================\nTotal test samples: 12010\nNormal samples: 7996 (66.58%)\nAttack samples: 4014 (33.42%)\n\nMean probability difference: 0.003006\nMax probability difference: 0.856499\n\nPrediction agreement rate: 0.9993 (99.93%)\nDisagreement cases: 9\n======================================================================\n\nAll results saved to: comparison_results/\n\n======================================================================\nANALYSIS COMPLETE!\n======================================================================\n\nConclusion:\n✓ INT8 quantization has MINIMAL IMPACT on model performance.\n  The quantized model is suitable for deployment.\n\nAll results saved to: comparison_results/\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}